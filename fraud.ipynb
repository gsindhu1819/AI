{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMH64ptNGCEWL8+o5hcOm8j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gsindhu1819/AI/blob/main/fraud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAYoAdNJjZMY",
        "outputId": "5e4c57c5-c999-4455-a791-d5a429380654"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time      0\n",
            "V1        0\n",
            "V2        0\n",
            "V3        0\n",
            "V4        0\n",
            "V5        0\n",
            "V6        0\n",
            "V7        0\n",
            "V8        0\n",
            "V9        0\n",
            "V10       0\n",
            "V11       0\n",
            "V12       0\n",
            "V13       0\n",
            "V14       0\n",
            "V15       0\n",
            "V16       0\n",
            "V17       0\n",
            "V18       0\n",
            "V19       0\n",
            "V20       0\n",
            "V21       0\n",
            "V22       0\n",
            "V23       0\n",
            "V24       0\n",
            "V25       0\n",
            "V26       0\n",
            "V27       0\n",
            "V28       0\n",
            "Amount    0\n",
            "Class     0\n",
            "dtype: int64\n",
            "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
            "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
            "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
            "       'Class'],\n",
            "      dtype='object')\n",
            "[[225408   2043]\n",
            " [   158    236]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00    227451\n",
            "           1       0.10      0.60      0.18       394\n",
            "\n",
            "    accuracy                           0.99    227845\n",
            "   macro avg       0.55      0.80      0.59    227845\n",
            "weighted avg       1.00      0.99      0.99    227845\n",
            "\n",
            "[[56321   543]\n",
            " [   30    68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     56864\n",
            "           1       0.11      0.69      0.19        98\n",
            "\n",
            "    accuracy                           0.99     56962\n",
            "   macro avg       0.56      0.84      0.59     56962\n",
            "weighted avg       1.00      0.99      0.99     56962\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "#load the dataset\n",
        "df=pd.read_csv('/content/creditcard.csv.zip')\n",
        "df\n",
        "\n",
        "#check for existing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print(df.columns)\n",
        "\n",
        "columns_to_drop=['Time','Amount']\n",
        "for column in columns_to_drop:\n",
        "  if column in df.columns:\n",
        "    df.drop([column],axis=1,inplace=True)\n",
        "\n",
        "x=df.drop('Class',axis=1)\n",
        "y=df['Class']\n",
        "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42,stratify=y)\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "#train the model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "#make prediction\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "#now lets implement an anomaly detection technique using the isolation forest algorithm.\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "#train  the isolation forest model\n",
        "iso_forest = IsolationForest(contamination=0.01,random_state=42)\n",
        "y_train_iso_pred = iso_forest.fit_predict(X_train)\n",
        "\n",
        "#convert predictions to binary\n",
        "y_train_iso_pred = [1 if x == -1 else 0 for x in y_train_iso_pred]\n",
        "\n",
        "#evaluate the model on the training set\n",
        "print(confusion_matrix(y_train,y_train_iso_pred))\n",
        "print(classification_report(y_train,y_train_iso_pred))\n",
        "\n",
        "#predict on the test set\n",
        "y_test_iso_pred = iso_forest.predict(X_test)\n",
        "y_test_iso_pred = [1 if x == -1 else 0 for x in y_test_iso_pred]\n",
        "\n",
        "#evaluate the model on the test set\n",
        "print(confusion_matrix(y_test,y_test_iso_pred))\n",
        "print(classification_report(y_test,y_test_iso_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vD_Rh8CzklsD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}